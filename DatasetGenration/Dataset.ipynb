{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afba58f-1bbe-48dd-91ff-7ca5a1be5bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries and functions for this tutorial.\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "from pydrake.all import (\n",
    "    AddMultibodyPlantSceneGraph,\n",
    "    DiagramBuilder,\n",
    "    Parser,\n",
    "    RandomGenerator,\n",
    "    RigidTransform,\n",
    "    Role,\n",
    "    RollPitchYaw,\n",
    "    Simulator,\n",
    "    UniformlyRandomRotationMatrix,\n",
    "    RotationMatrix\n",
    ")\n",
    "\n",
    "# from manipulation import running_as_notebook\n",
    "# from manipulation.scenarios import AddRgbdSensor\n",
    "# from manipulation.utils import colorize_labels\n",
    "\n",
    "from pydrake.common import FindResourceOrThrow, temp_directory\n",
    "from pydrake.geometry import (\n",
    "    MeshcatVisualizer,\n",
    "    MeshcatVisualizerParams,\n",
    "    Role,\n",
    "    StartMeshcat,\n",
    ")\n",
    "\n",
    "import sys\n",
    "\n",
    "from pydrake.multibody.meshcat import JointSliders\n",
    "from pydrake.multibody.parsing import Parser\n",
    "from glob import glob\n",
    "\n",
    "import multiprocessing as mp\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "import yaml\n",
    "\n",
    "import cv2\n",
    "\n",
    "import trimesh\n",
    "\n",
    "from pydrake.all import (\n",
    "    AbstractValue, Adder, AddMultibodyPlantSceneGraph, BallRpyJoint, BaseField,\n",
    "    Box, CameraInfo, ClippingRange, CoulombFriction, Cylinder, Demultiplexer,\n",
    "    DepthImageToPointCloud, DepthRange, DepthRenderCamera, DiagramBuilder,\n",
    "    FindResourceOrThrow, GeometryInstance, InverseDynamicsController,\n",
    "    LeafSystem, LoadModelDirectivesFromString,\n",
    "    MakeMultibodyStateToWsgStateSystem, MakePhongIllustrationProperties,\n",
    "    MakeRenderEngineVtk, ModelInstanceIndex, MultibodyPlant, Parser,\n",
    "    PassThrough, PrismaticJoint, ProcessModelDirectives, RenderCameraCore,\n",
    "    RenderEngineVtkParams, RevoluteJoint, Rgba, RgbdSensor, RigidTransform,\n",
    "    RollPitchYaw, RotationMatrix, SchunkWsgPositionController, SpatialInertia,\n",
    "    Sphere, StateInterpolatorWithDiscreteDerivative, UnitInertia)\n",
    "\n",
    "from pydrake.manipulation.planner import (\n",
    "    DifferentialInverseKinematicsIntegrator,\n",
    "    DifferentialInverseKinematicsParameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92979dc1-9370-4aaf-806b-4d3483c2216c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddRgbdSensor(builder,\n",
    "                  scene_graph,\n",
    "                  X_PC,\n",
    "                  depth_camera=None,\n",
    "                  renderer=None,\n",
    "                  parent_frame_id=None):\n",
    "    \"\"\"\n",
    "    Adds a RgbdSensor to to the scene_graph at (fixed) pose X_PC relative to\n",
    "    the parent_frame.  If depth_camera is None, then a default camera info will\n",
    "    be used.  If renderer is None, then we will assume the name 'my_renderer',\n",
    "    and create a VTK renderer if a renderer of that name doesn't exist.  If\n",
    "    parent_frame is None, then the world frame is used.\n",
    "    \"\"\"\n",
    "    if sys.platform == \"linux\" and os.getenv(\"DISPLAY\") is None:\n",
    "        from pyvirtualdisplay import Display\n",
    "        virtual_display = Display(visible=0, size=(1400, 900))\n",
    "        virtual_display.start()\n",
    "\n",
    "    if not renderer:\n",
    "        renderer = \"my_renderer\"\n",
    "\n",
    "    if not parent_frame_id:\n",
    "        parent_frame_id = scene_graph.world_frame_id()\n",
    "\n",
    "    if not scene_graph.HasRenderer(renderer):\n",
    "        scene_graph.AddRenderer(renderer,\n",
    "                                MakeRenderEngineVtk(RenderEngineVtkParams()))\n",
    "\n",
    "    if not depth_camera:\n",
    "        depth_camera = DepthRenderCamera(\n",
    "            RenderCameraCore(\n",
    "                renderer, CameraInfo(width=640, height=480, fov_y=np.pi / 4.0),\n",
    "                ClippingRange(near=0.1, far=10.0), RigidTransform()),\n",
    "            DepthRange(0.1, 10.0))\n",
    "\n",
    "    rgbd = builder.AddSystem(\n",
    "        RgbdSensor(parent_id=parent_frame_id,\n",
    "                   X_PB=X_PC,\n",
    "                   depth_camera=depth_camera,\n",
    "                   show_window=False))\n",
    "\n",
    "    builder.Connect(scene_graph.get_query_output_port(),\n",
    "                    rgbd.query_object_input_port())\n",
    "\n",
    "    return rgbd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db0a7a0-b6fc-4c19-a325-17cb2e1edbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = ['055_baseball.sdf',\n",
    " '056_tennis_ball.sdf',\n",
    " '072-a_toy_airplane.sdf',\n",
    " '019_pitcher_base.sdf',\n",
    " '040_large_marker.sdf',\n",
    " '021_bleach_cleanser.sdf',\n",
    " '077_rubiks_cube.sdf',\n",
    " '048_hammer.sdf',\n",
    " '008_pudding_box.sdf',\n",
    " '053_mini_soccer_ball.sdf',\n",
    " '011_banana.sdf',\n",
    " '006_mustard_bottle.sdf',\n",
    " '013_apple.sdf',\n",
    " '029_plate.sdf',\n",
    " '035_power_drill.sdf',\n",
    " '043_phillips_screwdriver.sdf',\n",
    " '032_knife.sdf',\n",
    " '042_adjustable_wrench.sdf']\n",
    "noise_objects = ['050_medium_clamp.sdf',\n",
    "'002_master_chef_can.sdf',\n",
    "'009_gelatin_box.sdf',\n",
    "'015_peach.sdf',\n",
    "'054_softball.sdf',\n",
    "'003_cracker_box.sdf',\n",
    "'012_strawberry.sdf',\n",
    "'026_sponge.sdf',\n",
    "'018_plum.sdf',\n",
    "'004_sugar_box.sdf',\n",
    "'014_lemon.sdf',\n",
    "'071_nine_hole_peg_test.sdf',\n",
    "'057_racquetball.sdf',\n",
    "'030_fork.sdf',\n",
    "'007_tuna_fish_can.sdf',\n",
    "'024_bowl.sdf',\n",
    "'062_dice.sdf',\n",
    "'037_scissors.sdf',\n",
    "'058_golf_ball.sdf',\n",
    "'052_extra_large_clamp.sdf',\n",
    "'044_flat_screwdriver.sdf',\n",
    "'061_foam_brick.sdf',\n",
    "'033_spatula.sdf',\n",
    "'016_pear.sdf',\n",
    "'025_mug.sdf',\n",
    "'010_potted_meat_can.sdf',\n",
    "'017_orange.sdf',\n",
    "'036_wood_block.sdf'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8d4cd-631f-466f-bc84-dba44d10bab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_dict = {}\n",
    "id_dict = {}\n",
    "mask_dict = {}\n",
    "mask_vals = np.linspace(0,255,len(objects)+1,dtype=np.int32)[1:]\n",
    "for i,this_object in enumerate(objects):\n",
    "    obj_dict[i] = this_object.replace('.sdf','')\n",
    "    id_dict[this_object.replace('.sdf','')] = i+1\n",
    "    mask_dict[this_object.replace('.sdf','')] = mask_vals[i]\n",
    "print(obj_dict)\n",
    "print(id_dict)\n",
    "print(mask_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbdebba-3cc7-4197-95cb-70b5bb22d93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('rm -r ./dataset/')\n",
    "os.system('mkdir ./dataset/' )\n",
    "os.system('mkdir ./dataset/rgb/')\n",
    "os.system('mkdir ./dataset/merged_masks/')\n",
    "os.system('mkdir ./dataset/masks/')\n",
    "os.system('mkdir ./dataset/depth/')\n",
    "for n in mask_dict.keys():\n",
    "    os.system('mkdir ./dataset/masks/' + n + '/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdd43da-3eaa-4ed1-8022-af53eb0c0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_imap_multiprocessing(func, argument_list, show_prog = True):\n",
    "    pool = mp.Pool(processes=mp.cpu_count())\n",
    "    \n",
    "    if show_prog:            \n",
    "        result_list_tqdm = []\n",
    "        for result in tqdm(pool.imap(func=func, iterable=argument_list), total=len(argument_list),position=0, leave=True):\n",
    "            result_list_tqdm.append(result)\n",
    "    else:\n",
    "        result_list_tqdm = []\n",
    "        for result in pool.imap(func=func, iterable=argument_list):\n",
    "            result_list_tqdm.append(result)\n",
    "\n",
    "    return result_list_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef1f016-3869-4aa2-b1ad-9996492b9696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sample(n):\n",
    "    np.random.seed(int.from_bytes(os.urandom(4), byteorder='little'))\n",
    "    rng = np.random.default_rng()  # this is for python\n",
    "    generator = RandomGenerator(rng.integers(1000))  # for c++\n",
    "    builder = DiagramBuilder()\n",
    "    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.0001)\n",
    "    parser = Parser(plant)\n",
    "    table_sdf = \"./table/table.sdf\"\n",
    "    parser.AddModelFromFile(table_sdf)\n",
    "    plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"table_body_link\"))\n",
    "\n",
    "    parser.AddModelFromFile(\"ground.sdf\")\n",
    "    plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"ground_link\"))\n",
    "\n",
    "    parser.AddModelFromFile(\"table_top.sdf\")\n",
    "    plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"table_top_link\"))\n",
    "\n",
    "\n",
    "    inspector = scene_graph.model_inspector()\n",
    "\n",
    "    instance_id_to_class_name = dict()\n",
    "    \n",
    "    n_target = np.random.randint(low=5,high=20)\n",
    "    rand_i = np.random.choice(len(objects),size=n_target)\n",
    "    n_noise = np.random.randint(low=5,high=10)\n",
    "    rand_i_n = np.random.choice(len(noise_objects),size=n_noise)\n",
    "    \n",
    "    for object_num in range(n_target):\n",
    "\n",
    "        this_object = objects[rand_i[object_num]]\n",
    "        class_name = this_object.split('.')[0]\n",
    "        sdf = \"./ycb/sdf/\"+ this_object\n",
    "        instance = parser.AddModelFromFile(sdf, f\"object{class_name}_%i\"%(object_num))\n",
    "\n",
    "        frame_id = plant.GetBodyFrameIdOrThrow(\n",
    "            plant.GetBodyIndices(instance)[0])\n",
    "        geometry_ids = inspector.GetGeometries(frame_id, Role.kPerception)\n",
    "        for geom_id in geometry_ids:\n",
    "            instance_id_to_class_name[int(\n",
    "                inspector.GetPerceptionProperties(geom_id).GetProperty(\n",
    "                    \"label\", \"id\"))] = class_name\n",
    "\n",
    "    for object_num in range(n_noise):\n",
    "\n",
    "        this_object = noise_objects[rand_i_n[object_num]]\n",
    "        class_name = this_object.split('.')[0]\n",
    "        sdf = \"./ycb/sdf/\"+ this_object\n",
    "        instance = parser.AddModelFromFile(sdf, f\"object{class_name}_%i\"%(object_num))\n",
    "            \n",
    "    plant.Finalize()\n",
    "\n",
    "    thetas = np.linspace(0,np.pi,20)\n",
    "    if np.random.uniform()<0.5:\n",
    "        p1 = np.random.uniform(low=[-0.3,-0.2,0.5],high=[-0.3,0.2,0.5])\n",
    "    else:\n",
    "        p1 = np.random.uniform(low=[-0.3,-0.2,0.5],high=[0.3,-0.2,0.5])\n",
    "    p2 = -p1\n",
    "    p2[-1] = 0.5\n",
    "\n",
    "    l = p1-p2\n",
    "    l = l[0:2]/np.linalg.norm(l[0:2])\n",
    "    p1[0:2] = p1[0:2] + l * 1.0\n",
    "    p2[0:2] = p2[0:2] - l * 1.0\n",
    "    r = np.linalg.norm(p1[0:2]-p2[0:2])/2\n",
    "    cc = (p1[0:2]+p2[0:2])/2\n",
    "    r_u = p1[0:2] - cc\n",
    "    cameras = []\n",
    "    for i in range(20):\n",
    "        # pick two points on the table to circle over\n",
    "        rr = r_u * np.cos(thetas[i])\n",
    "        zr = r * np.sin(thetas[i])\n",
    "        p = cc + rr\n",
    "        p = np.array([p[0],p[1],zr+0.5])\n",
    "        r_c = np.array([0.,0.,0.4]-p)\n",
    "        r_c = r_c/np.linalg.norm(r_c)\n",
    "        c_uv = np.array([0.,0.,1.])\n",
    "        v = np.cross(c_uv,r_c)\n",
    "        s = np.linalg.norm(v)\n",
    "        c = np.dot(c_uv,r_c)\n",
    "        v_c = np.array([[0,-v[2],v[1]],\n",
    "                        [v[2],0,-v[0]],\n",
    "                        [-v[1],v[0],0]])\n",
    "        R = np.eye(3) + v_c + v_c@v_c * ((1-c)/s**2)\n",
    "\n",
    "        cameras.append(AddRgbdSensor(\n",
    "            builder, scene_graph,\n",
    "            RigidTransform(RotationMatrix(R), p)))\n",
    "        cameras[-1].set_name(\"rgbd_sensor_\" + str(i+1))\n",
    "        builder.ExportOutput(cameras[-1].color_image_output_port(), \"color_image_\" + str(i+1))\n",
    "        builder.ExportOutput(cameras[-1].label_image_output_port(), \"label_image_\" + str(i+1))\n",
    "        builder.ExportOutput(cameras[-1].depth_image_32F_output_port(),\"depth_image_\" + str(i+1))\n",
    "        builder.ExportOutput(cameras[-1].body_pose_in_world_output_port(),\"camera_pose_\" + str(i+1))\n",
    "\n",
    "    diagram = builder.Build()\n",
    "    cc = 0\n",
    "    while True:\n",
    "        simulator = Simulator(diagram)\n",
    "        context = simulator.get_mutable_context()\n",
    "        plant_context = plant.GetMyContextFromRoot(context)\n",
    "\n",
    "        z = 0.6\n",
    "        c = 0\n",
    "        for body_index in plant.GetFloatingBaseBodies():\n",
    "            tf = RigidTransform(\n",
    "                UniformlyRandomRotationMatrix(generator),\n",
    "                np.random.uniform(low=[-0.3,-0.2,0.5 + c * 0.1],high=[0.3,0.2,0.5 + c * 0.1],size=3).tolist())\n",
    "            # tf = RigidTransform()\n",
    "            # tf.set_translation([-0.5 + (c%5)*0.2,-0.2 + (c//5) * 0.2, 1.0])\n",
    "            c += 1\n",
    "            plant.SetFreeBodyPose(plant_context, plant.get_body(body_index), tf)\n",
    "            z += 0.1\n",
    "\n",
    "        try:\n",
    "            simulator.AdvanceTo(3.0)\n",
    "            break\n",
    "        except RuntimeError:\n",
    "            # I've chosen an aggressive simulation time step which works most\n",
    "            # of the time, but can fail occasionally.\n",
    "            pass\n",
    "        if cc>=100:\n",
    "            return generate_sample(n)\n",
    "        cc += 1\n",
    "    pose_output = []\n",
    "    for i in range(20):\n",
    "        img_i = n*20 + i\n",
    "        color_image = diagram.GetOutputPort(\"color_image_%i\"%(i+1)).Eval(context)\n",
    "        label_image = diagram.GetOutputPort(\"label_image_%i\"%(i+1)).Eval(context)\n",
    "        depth_image = diagram.GetOutputPort(\"depth_image_%i\"%(i+1)).Eval(context)\n",
    "        X_WC = diagram.GetOutputPort(\"camera_pose_%i\"%(i+1)).Eval(context)\n",
    "        X_CW = X_WC.inverse()\n",
    "        \n",
    "        im = Image.fromarray(color_image.data)\n",
    "        im.save('./dataset/rgb/%i.png'% img_i)\n",
    "        \n",
    "        np.save('./dataset/depth/%i.npy'% img_i,depth_image.data)\n",
    "        \n",
    "        instance_id_to_pos = dict()\n",
    "\n",
    "        for body_index in plant.GetFloatingBaseBodies():\n",
    "            instance_id_to_pos[int(body_index)] = X_CW @ plant.GetFreeBodyPose(plant_context, plant.get_body(body_index))\n",
    "            \n",
    "        visible_objects = np.unique(label_image.mutable_data)\n",
    "        \n",
    "        poses = []\n",
    "        merged_mask = np.zeros_like(label_image.mutable_data.squeeze()).astype(np.uint8)\n",
    "        \n",
    "        instance_count = {}\n",
    "        \n",
    "        for k in mask_dict.keys():\n",
    "            instance_count[k] = 0\n",
    "        \n",
    "        for i,c in enumerate(instance_id_to_class_name):\n",
    "            if c in visible_objects:\n",
    "                mask = label_image.mutable_data == c\n",
    "                pos = np.where(mask)\n",
    "                xmin = np.min(pos[1])\n",
    "                xmax = np.max(pos[1])\n",
    "                ymin = np.min(pos[0])\n",
    "                ymax = np.max(pos[0])\n",
    "                \n",
    "                if mask.sum() > 9 and xmin<xmax and ymin<ymax:\n",
    "                    im = Image.fromarray((mask*255).astype(np.uint8).squeeze())\n",
    "                    im.save('./dataset/masks/'+ instance_id_to_class_name[c] + '/%i.png'% img_i)\n",
    "                    poses.append([instance_id_to_class_name[c],instance_id_to_pos[c].translation(),instance_id_to_pos[c].rotation().matrix()])\n",
    "                    mask_val = mask_dict[instance_id_to_class_name[c]] - instance_count[instance_id_to_class_name[c]]\n",
    "                    instance_count[instance_id_to_class_name[c]] += 1\n",
    "                    if instance_count[instance_id_to_class_name[c]] > 10:\n",
    "                        return generate_sample(n)\n",
    "                    merged_mask += mask.astype(np.uint8).squeeze() * mask_val\n",
    "        \n",
    "        im = Image.fromarray(merged_mask)\n",
    "        im.save('./dataset/merged_masks/%i.png'% img_i)\n",
    "        \n",
    "        pose_output.append((img_i,poses))\n",
    "        \n",
    "    return pose_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a4e581-8973-4374-a24a-2c1e8e5f0916",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_out = run_imap_multiprocessing(generate_sample,list(range(1250)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbdb387-517b-4e54-98d1-145ff729b8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "poses = []\n",
    "cam_K = [579.4112549695428, 0.0, 319.5, 0.0, 579.4112549695428, 239.5, 0.0, 0.0, 1.0]\n",
    "for p in pos_out:\n",
    "    poses += p\n",
    "\n",
    "if not 'ground_truth' in locals():\n",
    "    ground_truth = {}\n",
    "\n",
    "for p in poses:\n",
    "    pose_list = []\n",
    "    for item in p[1]:\n",
    "        pose_list.append({'cam_R_m2c':item[2].flatten().tolist(),'cam_t_m2c':item[1].flatten().tolist(),'obj_id': id_dict[item[0]],'cam_K': cam_K})\n",
    "    ground_truth[p[0]] = pose_list\n",
    "    \n",
    "with open(r'./dataset/gt.yml', 'w') as file:\n",
    "    documents = yaml.dump(ground_truth, file,default_flow_style=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
